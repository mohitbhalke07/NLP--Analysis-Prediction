{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport string\nimport nltk\nimport nltk.corpus\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"train.csv\")","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Understanding","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I grew up (b. 1965) watching and loving the Th...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>When I put this movie in my DVD player, and sa...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Why do people who do not know what a particula...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Even though I have great interest in Biblical ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Im a die hard Dads Army fan and nothing will e...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  I grew up (b. 1965) watching and loving the Th...      0\n","1  When I put this movie in my DVD player, and sa...      0\n","2  Why do people who do not know what a particula...      0\n","3  Even though I have great interest in Biblical ...      0\n","4  Im a die hard Dads Army fan and nothing will e...      1"]},"metadata":{}}]},{"cell_type":"code","source":"data.shape","metadata":{},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":["(40000, 2)"]},"metadata":{}}]},{"cell_type":"code","source":"data.sample(10)","metadata":{},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24654</th>\n","      <td>I only bought this DVD because it was dirt che...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3283</th>\n","      <td>This is a romantic comedy with the emphasis on...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8366</th>\n","      <td>This is a wonderful comedy short--one of Keato...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>35069</th>\n","      <td>definitely the best game for N64 ever. I most ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16936</th>\n","      <td>I'm both amused and disgusted by the people wh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2327</th>\n","      <td>I was very interested in seeing this movie des...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7787</th>\n","      <td>ONCE UPON A TIME, there were different types o...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9665</th>\n","      <td>I had read many good things about this adaptat...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12264</th>\n","      <td>I first remember seeing this one back in the 7...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>36561</th>\n","      <td>My complaints here concern the movie's pacing ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    text  label\n","24654  I only bought this DVD because it was dirt che...      0\n","3283   This is a romantic comedy with the emphasis on...      1\n","8366   This is a wonderful comedy short--one of Keato...      1\n","35069  definitely the best game for N64 ever. I most ...      1\n","16936  I'm both amused and disgusted by the people wh...      0\n","2327   I was very interested in seeing this movie des...      0\n","7787   ONCE UPON A TIME, there were different types o...      1\n","9665   I had read many good things about this adaptat...      0\n","12264  I first remember seeing this one back in the 7...      1\n","36561  My complaints here concern the movie's pacing ...      0"]},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\n\nRangeIndex: 40000 entries, 0 to 39999\n\nData columns (total 2 columns):\n\n #   Column  Non-Null Count  Dtype \n\n---  ------  --------------  ----- \n\n 0   text    40000 non-null  object\n\n 1   label   40000 non-null  int64 \n\ndtypes: int64(1), object(1)\n\nmemory usage: 625.1+ KB\n"}]},{"cell_type":"code","source":"data.isnull().mean()*100","metadata":{},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":["text     0.0\n","label    0.0\n","dtype: float64"]},"metadata":{}}]},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":["277"]},"metadata":{}}]},{"cell_type":"code","source":"data[data[\"text\"].duplicated()].head()","metadata":{},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2164</th>\n","      <td>I find it rather useless to comment on this \"m...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3236</th>\n","      <td>An absolutely atrocious adaptation of the wond...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3428</th>\n","      <td>When I first saw this film it was not an impre...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3652</th>\n","      <td>Before I watched this tv movie I did not know ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3787</th>\n","      <td>What a clunker!&lt;br /&gt;&lt;br /&gt;It MUST have been m...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   text  label\n","2164  I find it rather useless to comment on this \"m...      0\n","3236  An absolutely atrocious adaptation of the wond...      0\n","3428  When I first saw this film it was not an impre...      0\n","3652  Before I watched this tv movie I did not know ...      1\n","3787  What a clunker!<br /><br />It MUST have been m...      0"]},"metadata":{}}]},{"cell_type":"code","source":"data.drop_duplicates(inplace=True)","metadata":{},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning / Preprocessing","metadata":{}},{"cell_type":"code","source":"data[\"text\"][0]","metadata":{},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":["'I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.'"]},"metadata":{}}]},{"cell_type":"code","source":"data[\"label\"].value_counts()","metadata":{},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":["1    19908\n","0    19815\n","Name: label, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"#TOKENISATION AND REMOVING PUNCTUATIONS\n\ndef preprocessing1(text):\n    tokens = word_tokenize(text)\n    \n    punctuations = string.punctuation\n    txt = []\n    for i in tokens:\n        if i not in punctuations:\n            txt.append(i)\n    return txt","metadata":{},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data[\"text\"] = data[\"text\"].apply(preprocessing1)","metadata":{},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data[\"text\"][0]","metadata":{},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":["['I',\n"," 'grew',\n"," 'up',\n"," 'b',\n"," '1965',\n"," 'watching',\n"," 'and',\n"," 'loving',\n"," 'the',\n"," 'Thunderbirds',\n"," 'All',\n"," 'my',\n"," 'mates',\n"," 'at',\n"," 'school',\n"," 'watched',\n"," 'We',\n"," 'played',\n"," '``',\n"," 'Thunderbirds',\n"," \"''\",\n"," 'before',\n"," 'school',\n"," 'during',\n"," 'lunch',\n"," 'and',\n"," 'after',\n"," 'school',\n"," 'We',\n"," 'all',\n"," 'wanted',\n"," 'to',\n"," 'be',\n"," 'Virgil',\n"," 'or',\n"," 'Scott',\n"," 'No',\n"," 'one',\n"," 'wanted',\n"," 'to',\n"," 'be',\n"," 'Alan',\n"," 'Counting',\n"," 'down',\n"," 'from',\n"," '5',\n"," 'became',\n"," 'an',\n"," 'art',\n"," 'form',\n"," 'I',\n"," 'took',\n"," 'my',\n"," 'children',\n"," 'to',\n"," 'see',\n"," 'the',\n"," 'movie',\n"," 'hoping',\n"," 'they',\n"," 'would',\n"," 'get',\n"," 'a',\n"," 'glimpse',\n"," 'of',\n"," 'what',\n"," 'I',\n"," 'loved',\n"," 'as',\n"," 'a',\n"," 'child',\n"," 'How',\n"," 'bitterly',\n"," 'disappointing',\n"," 'The',\n"," 'only',\n"," 'high',\n"," 'point',\n"," 'was',\n"," 'the',\n"," 'snappy',\n"," 'theme',\n"," 'tune',\n"," 'Not',\n"," 'that',\n"," 'it',\n"," 'could',\n"," 'compare',\n"," 'with',\n"," 'the',\n"," 'original',\n"," 'score',\n"," 'of',\n"," 'the',\n"," 'Thunderbirds',\n"," 'Thankfully',\n"," 'early',\n"," 'Saturday',\n"," 'mornings',\n"," 'one',\n"," 'television',\n"," 'channel',\n"," 'still',\n"," 'plays',\n"," 'reruns',\n"," 'of',\n"," 'the',\n"," 'series',\n"," 'Gerry',\n"," 'Anderson',\n"," 'and',\n"," 'his',\n"," 'wife',\n"," 'created',\n"," 'Jonatha',\n"," 'Frakes',\n"," 'should',\n"," 'hand',\n"," 'in',\n"," 'his',\n"," 'directors',\n"," 'chair',\n"," 'his',\n"," 'version',\n"," 'was',\n"," 'completely',\n"," 'hopeless',\n"," 'A',\n"," 'waste',\n"," 'of',\n"," 'film',\n"," 'Utter',\n"," 'rubbish',\n"," 'A',\n"," 'CGI',\n"," 'remake',\n"," 'may',\n"," 'be',\n"," 'acceptable',\n"," 'but',\n"," 'replacing',\n"," 'marionettes',\n"," 'with',\n"," 'Homo',\n"," 'sapiens',\n"," 'subsp',\n"," 'sapiens',\n"," 'was',\n"," 'a',\n"," 'huge',\n"," 'error',\n"," 'of',\n"," 'judgment']"]},"metadata":{}}]},{"cell_type":"code","source":"#REMOVING STOPWORDS & CONVERTING TO LOWERCASE\n\ndef preprocessing2(text):\n    stopword = stopwords.words(\"english\")\n    ntxt = []\n    for j in text:\n        if j not in stopword:\n            ntxt.append(j.lower())\n    return ntxt","metadata":{},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data[\"text\"] = data[\"text\"].apply(preprocessing2)","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data[\"text\"][0]","metadata":{"scrolled":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'grew',\n"," 'b',\n"," '1965',\n"," 'watching',\n"," 'loving',\n"," 'thunderbirds',\n"," 'all',\n"," 'mates',\n"," 'school',\n"," 'watched',\n"," 'we',\n"," 'played',\n"," '``',\n"," 'thunderbirds',\n"," \"''\",\n"," 'school',\n"," 'lunch',\n"," 'school',\n"," 'we',\n"," 'wanted',\n"," 'virgil',\n"," 'scott',\n"," 'no',\n"," 'one',\n"," 'wanted',\n"," 'alan',\n"," 'counting',\n"," '5',\n"," 'became',\n"," 'art',\n"," 'form',\n"," 'i',\n"," 'took',\n"," 'children',\n"," 'see',\n"," 'movie',\n"," 'hoping',\n"," 'would',\n"," 'get',\n"," 'glimpse',\n"," 'i',\n"," 'loved',\n"," 'child',\n"," 'how',\n"," 'bitterly',\n"," 'disappointing',\n"," 'the',\n"," 'high',\n"," 'point',\n"," 'snappy',\n"," 'theme',\n"," 'tune',\n"," 'not',\n"," 'could',\n"," 'compare',\n"," 'original',\n"," 'score',\n"," 'thunderbirds',\n"," 'thankfully',\n"," 'early',\n"," 'saturday',\n"," 'mornings',\n"," 'one',\n"," 'television',\n"," 'channel',\n"," 'still',\n"," 'plays',\n"," 'reruns',\n"," 'series',\n"," 'gerry',\n"," 'anderson',\n"," 'wife',\n"," 'created',\n"," 'jonatha',\n"," 'frakes',\n"," 'hand',\n"," 'directors',\n"," 'chair',\n"," 'version',\n"," 'completely',\n"," 'hopeless',\n"," 'a',\n"," 'waste',\n"," 'film',\n"," 'utter',\n"," 'rubbish',\n"," 'a',\n"," 'cgi',\n"," 'remake',\n"," 'may',\n"," 'acceptable',\n"," 'replacing',\n"," 'marionettes',\n"," 'homo',\n"," 'sapiens',\n"," 'subsp',\n"," 'sapiens',\n"," 'huge',\n"," 'error',\n"," 'judgment']"]},"metadata":{}}]},{"cell_type":"code","source":"#STEMMING\n\ndef preprocessing3(text):\n    stem = []\n    Stemmer = PorterStemmer()\n    for i in text:\n        stem.append(Stemmer.stem(i))\n    return \" \".join(stem)","metadata":{},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data[\"text\"] = data[\"text\"].apply(preprocessing3)","metadata":{},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data[\"text\"][0]","metadata":{},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":["\"i grew b 1965 watch love thunderbird all mate school watch we play `` thunderbird '' school lunch school we want virgil scott no one want alan count 5 becam art form i took children see movi hope would get glimps i love child how bitterli disappoint the high point snappi theme tune not could compar origin score thunderbird thank earli saturday morn one televis channel still play rerun seri gerri anderson wife creat jonatha frake hand director chair version complet hopeless a wast film utter rubbish a cgi remak may accept replac marionett homo sapien subsp sapien huge error judgment\""]},"metadata":{}}]},{"cell_type":"code","source":"# REMOVING HTML TAGS\n\ndef preprocessing4(text):\n    pattern = re.compile(\"<.*?>\")\n    return pattern.sub(r'',text)","metadata":{},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"data[\"text\"] = data[\"text\"].apply(preprocessing4)","metadata":{"scrolled":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>i grew b 1965 watch love thunderbird all mate ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>when i put movi dvd player sat coke chip i exp...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>whi peopl know particular time past like feel ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>even though i great interest biblic movi i bor...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>im die hard dad armi fan noth ever chang i got...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>a terribl movi everyon said what made laugh ca...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>final watch shock movi last night disturb mind...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>i caught film azn cabl it sound like would goo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>it may remak 1987 autumn 's tale eleven year d...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>my super ex girlfriend turn pleasant surpris i...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  i grew b 1965 watch love thunderbird all mate ...      0\n","1  when i put movi dvd player sat coke chip i exp...      0\n","2  whi peopl know particular time past like feel ...      0\n","3  even though i great interest biblic movi i bor...      0\n","4  im die hard dad armi fan noth ever chang i got...      1\n","5  a terribl movi everyon said what made laugh ca...      0\n","6  final watch shock movi last night disturb mind...      1\n","7  i caught film azn cabl it sound like would goo...      0\n","8  it may remak 1987 autumn 's tale eleven year d...      1\n","9  my super ex girlfriend turn pleasant surpris i...      1"]},"metadata":{}}]},{"cell_type":"code","source":"data.isna().sum()","metadata":{},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":["text     0\n","label    0\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL BUILDING","metadata":{}},{"cell_type":"code","source":"x = data[\"text\"]\ny = data[\"label\"]","metadata":{},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer()\nx = tfidf.fit_transform(x)","metadata":{"scrolled":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=None)","metadata":{},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"logr = LogisticRegression()\nmodel = logr.fit(x_train,y_train)\npred = model.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":["88.60918816865954"]},"metadata":{}}]},{"cell_type":"code","source":"score = []\nfor i in range(20):\n    x = data[\"text\"]\n    y = data[\"label\"]\n    x = tfidf.fit_transform(x)\n    \n    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=i)\n    \n    logr = LogisticRegression()\n    logr.fit(x_train, y_train)\n    pred = logr.predict(x_test)\n    score.append(accuracy_score(y_test,pred)*100)\nprint(\"i= \",np.argmax(score))\nprint(score[np.argmax(score)])","metadata":{"scrolled":true},"execution_count":30,"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\n\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n\n    https://scikit-learn.org/stable/modules/preprocessing.html\n\nPlease also refer to the documentation for alternative solver options:\n\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n  n_iter_i = _check_optimize_result(\n\nC:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\n\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n\n    https://scikit-learn.org/stable/modules/preprocessing.html\n\nPlease also refer to the documentation for alternative solver options:\n\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n  n_iter_i = _check_optimize_result(\n\nC:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\n\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n\n    https://scikit-learn.org/stable/modules/preprocessing.html\n\nPlease also refer to the documentation for alternative solver options:\n\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n  n_iter_i = _check_optimize_result(\n\nC:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\n\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n\n    https://scikit-learn.org/stable/modules/preprocessing.html\n\nPlease also refer to the documentation for alternative solver options:\n\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n  n_iter_i = _check_optimize_result(\n"},{"name":"stdout","output_type":"stream","text":"i=  19\n\n89.56576463184392\n"}]},{"cell_type":"code","source":"logr = LogisticRegression()\nx = data[\"text\"]\ny = data[\"label\"]\nx = tfidf.fit_transform(x)\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n\nmodel1 = logr.fit(x_train,y_train)\npred = model1.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":["89.56576463184392"]},"metadata":{}}]},{"cell_type":"code","source":"# Training Data Accuracy\n\npred = model1.predict(x_train)\naccuracy_score(y_train, pred)*100     #Generalized","metadata":{},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":["92.65214928566932"]},"metadata":{}}]},{"cell_type":"code","source":"#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n\nmod1 = cross_val_score(LogisticRegression(), x_train, y_train, cv=10)\nprint(mod1)\nprint(np.round(np.mean(mod1),2)*100)","metadata":{},"execution_count":33,"outputs":[{"name":"stdout","output_type":"stream","text":"[0.89175582 0.88451857 0.88955318 0.89049717 0.89207048 0.88042794\n\n 0.88105727 0.89395846 0.88857413 0.88668555]\n\n89.0\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decision Tree Classifier**","metadata":{}},{"cell_type":"code","source":"dtc = DecisionTreeClassifier(random_state=4)\nmodel = dtc.fit(x_train,y_train)\npred = model.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":["71.16425424795469"]},"metadata":{}}]},{"cell_type":"code","source":"dtc = DecisionTreeClassifier(random_state=4)\nx = data[\"text\"]\ny = data[\"label\"]\nx = tfidf.fit_transform(x)\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=19)\n\nmodel2 = dtc.fit(x_train,y_train)\npred = model2.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":["71.16425424795469"]},"metadata":{}}]},{"cell_type":"code","source":"# Training Data Accuracy\n\npred = model2.predict(x_train)\naccuracy_score(y_train, pred)*100     #Overfitting","metadata":{},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":["100.0"]},"metadata":{}}]},{"cell_type":"code","source":"#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n\nmod2 = cross_val_score(DecisionTreeClassifier(random_state=4), x_train, y_train, cv=5)\nprint(mod2)\nprint(np.round(np.mean(mod2),2)*100)","metadata":{},"execution_count":37,"outputs":[{"name":"stdout","output_type":"stream","text":"[0.71585903 0.70232851 0.70736312 0.71738788 0.7202203 ]\n\n71.0\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RandomForest Classifier**","metadata":{}},{"cell_type":"code","source":"rfc = RandomForestClassifier(random_state=4)\nmodel = rfc.fit(x_train,y_train)\npred = model.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":["86.1296412838263"]},"metadata":{}}]},{"cell_type":"code","source":"rfc = RandomForestClassifier()\nx = data[\"text\"]\ny = data[\"label\"]\nx = tfidf.fit_transform(x)\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=19)\n\nmodel3 = rfc.fit(x_train,y_train)\npred = model3.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":["85.43738200125865"]},"metadata":{}}]},{"cell_type":"code","source":"# Training Data Accuracy\n\npred = model3.predict(x_train)\naccuracy_score(y_train, pred)*100     #Overfitting","metadata":{},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":["100.0"]},"metadata":{}}]},{"cell_type":"code","source":"#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n\nmod3 = cross_val_score(RandomForestClassifier(random_state=4), x_train, y_train, cv=3)\nprint(mod3)\nprint(np.round(np.mean(mod3),2)*100)","metadata":{},"execution_count":41,"outputs":[{"name":"stdout","output_type":"stream","text":"[0.84319834 0.83895025 0.84072885]\n\n84.0\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Support Vector Classifier**","metadata":{}},{"cell_type":"code","source":"svc = SVC(kernel=\"linear\",tol=0.1)\nmodel = svc.fit(x_train,y_train)\npred = model.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":["89.70421648835746"]},"metadata":{}}]},{"cell_type":"code","source":"svc = SVC(kernel=\"linear\",tol=0.1)\nx = data[\"text\"]\ny = data[\"label\"]\nx = tfidf.fit_transform(x)\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n\nmodel4 = svc.fit(x_train,y_train)\npred = model4.predict(x_test)\naccuracy_score(y_test, pred)*100","metadata":{"scrolled":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":["89.70421648835746"]},"metadata":{}}]},{"cell_type":"code","source":"# Training Data Accuracy\n\npred = model4.predict(x_train)\naccuracy_score(y_train, pred)*100     #Underfitting","metadata":{},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":["95.2766064572975"]},"metadata":{}}]},{"cell_type":"code","source":"#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n\nmod4 = cross_val_score(SVC(kernel=\"linear\",tol=0.1), x_train, y_train, cv=4)\nprint(mod4)\nprint(np.round(np.mean(mod4),2)*100)","metadata":{},"execution_count":47,"outputs":[{"name":"stdout","output_type":"stream","text":"[0.88999371 0.89011957 0.88381168 0.88783988]\n\n89.0\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}