{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea84acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7c033f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"financial sentiment analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97834eb",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40211ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0903dd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7697f3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Pretax loss totaled EUR 117mn compared to a lo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>Also , Technopolis plans to build a 100 millio...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>Severn Trent share price jumps as Canadian inv...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>The outsourced Scan and Capture solutions tran...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>The dividend will be paid on April 15 , 2008 t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>The financial details of the transaction were ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>Tampere Science Parks is a Finnish company tha...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>These savings will have full impact as of the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>Export accounts for about one tenth of the com...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>Operating profit fell to EUR 23.26 mn from EUR...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "259   Pretax loss totaled EUR 117mn compared to a lo...   neutral\n",
       "3484  Also , Technopolis plans to build a 100 millio...   neutral\n",
       "4136  Severn Trent share price jumps as Canadian inv...  positive\n",
       "5690  The outsourced Scan and Capture solutions tran...   neutral\n",
       "2423  The dividend will be paid on April 15 , 2008 t...   neutral\n",
       "2910  The financial details of the transaction were ...   neutral\n",
       "3281  Tampere Science Parks is a Finnish company tha...   neutral\n",
       "3708  These savings will have full impact as of the ...   neutral\n",
       "2150  Export accounts for about one tenth of the com...   neutral\n",
       "5492  Operating profit fell to EUR 23.26 mn from EUR...   neutral"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f74211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b3dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     0.0\n",
       "Sentiment    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab17ccd",
   "metadata": {},
   "source": [
    "# Data Cleaning / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f702ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the geosolut technolog leverag benefon 's gp solut provid locat base search technolog commun platform locat relev multimedia content new power commerci model\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ddaf8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3130\n",
       "positive    1852\n",
       "negative     860\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a04d0d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TOKENISATION AND REMOVING PUNCTUATIONS\n",
    "\n",
    "def preprocessing1(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    punctuations = string.punctuation\n",
    "    txt = []\n",
    "    for i in tokens:\n",
    "        if i not in punctuations:\n",
    "            txt.append(i)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73e00206",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentence\"] = data[\"Sentence\"].apply(preprocessing1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a60481ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'GeoSolutions',\n",
       " 'technology',\n",
       " 'will',\n",
       " 'leverage',\n",
       " 'Benefon',\n",
       " \"'s\",\n",
       " 'GPS',\n",
       " 'solutions',\n",
       " 'by',\n",
       " 'providing',\n",
       " 'Location',\n",
       " 'Based',\n",
       " 'Search',\n",
       " 'Technology',\n",
       " 'a',\n",
       " 'Communities',\n",
       " 'Platform',\n",
       " 'location',\n",
       " 'relevant',\n",
       " 'multimedia',\n",
       " 'content',\n",
       " 'and',\n",
       " 'a',\n",
       " 'new',\n",
       " 'and',\n",
       " 'powerful',\n",
       " 'commercial',\n",
       " 'model']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3f42da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING STOPWORDS & CONVERTING TO LOWERCASE\n",
    "\n",
    "def preprocessing2(text):\n",
    "    stopword = stopwords.words(\"english\")\n",
    "    ntxt = []\n",
    "    for j in text:\n",
    "        if j not in stopword:\n",
    "            ntxt.append(j.lower())\n",
    "    return ntxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91369436",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentence\"] = data[\"Sentence\"].apply(preprocessing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a135f4be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'geosolutions',\n",
       " 'technology',\n",
       " 'leverage',\n",
       " 'benefon',\n",
       " \"'s\",\n",
       " 'gps',\n",
       " 'solutions',\n",
       " 'providing',\n",
       " 'location',\n",
       " 'based',\n",
       " 'search',\n",
       " 'technology',\n",
       " 'communities',\n",
       " 'platform',\n",
       " 'location',\n",
       " 'relevant',\n",
       " 'multimedia',\n",
       " 'content',\n",
       " 'new',\n",
       " 'powerful',\n",
       " 'commercial',\n",
       " 'model']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95380a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEMMING\n",
    "\n",
    "def preprocessing3(text):\n",
    "    stem = []\n",
    "    Stemmer = PorterStemmer()\n",
    "    for i in text:\n",
    "        stem.append(Stemmer.stem(i))\n",
    "    return \" \".join(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a85e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentence\"] = data[\"Sentence\"].apply(preprocessing3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a808ec8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the geosolut technolog leverag benefon 's gp solut provid locat base search technolog commun platform locat relev multimedia content new power commerci model\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47d96c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the geosolut technolog leverag benefon 's gp s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esi low 1.50 2.50 bk real possibl</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for last quarter 2010 componenta 's net sale d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accord finnish-russian chamber commerc major c...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the swedish buyout firm sold remain 22.4 perce...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spi would n't surpris see green close</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shell 's 70 billion bg deal meet sharehold ske...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ssh commun secur corp stock exchang releas oct...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kone 's net sale rose 14 year-on-year first ni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the stockmann depart store total floor space 8...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  the geosolut technolog leverag benefon 's gp s...  positive\n",
       "1                  esi low 1.50 2.50 bk real possibl  negative\n",
       "2  for last quarter 2010 componenta 's net sale d...  positive\n",
       "3  accord finnish-russian chamber commerc major c...   neutral\n",
       "4  the swedish buyout firm sold remain 22.4 perce...   neutral\n",
       "5              spi would n't surpris see green close  positive\n",
       "6  shell 's 70 billion bg deal meet sharehold ske...  negative\n",
       "7  ssh commun secur corp stock exchang releas oct...  negative\n",
       "8  kone 's net sale rose 14 year-on-year first ni...  positive\n",
       "9  the stockmann depart store total floor space 8...   neutral"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e21dea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aed6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a14134c7",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62cbfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"Sentence\"]\n",
    "y = data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b04ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee71cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c21fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba034b",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52ea9ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.88879384088965"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "model = logr.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1938370c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mohit\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  11\n",
      "71.08639863130881\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(20):\n",
    "    x = data[\"Sentence\"]\n",
    "    y = data[\"Sentiment\"]\n",
    "    x = tfidf.fit_transform(x).toarray()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(x_train, y_train)\n",
    "    pred = logr.predict(x_test)\n",
    "    score.append(accuracy_score(y_test,pred)*100)\n",
    "print(\"i= \",np.argmax(score))\n",
    "print(score[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43d08f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.08639863130881"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "x = data[\"Sentence\"]\n",
    "y = data[\"Sentiment\"]\n",
    "x = tfidf.fit_transform(x).toarray()\n",
    "y = le.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n",
    "\n",
    "model1 = logr.fit(x_train,y_train)\n",
    "pred = model1.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e2a0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.60796062486625"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Accuracy\n",
    "\n",
    "pred = model1.predict(x_train)\n",
    "accuracy_score(y_train, pred)*100     #Generalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3b26969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70512821 0.6965812  0.67307692 0.69164882 0.68522484 0.67880086\n",
      " 0.70877944 0.68094218 0.67665953 0.70235546]\n",
      "69.0\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n",
    "\n",
    "mod1 = cross_val_score(LogisticRegression(), x_train, y_train, cv=10)\n",
    "print(mod1)\n",
    "print(np.round(np.mean(mod1),2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142ae57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "414172fb",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "984c2dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.53806672369547"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "model = dtc.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3989944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  16\n",
      "62.01881950384944\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(50):\n",
    "    x = data[\"Sentence\"]\n",
    "    y = data[\"Sentiment\"]\n",
    "    x = tfidf.fit_transform(x).toarray()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(x_train, y_train)\n",
    "    pred = dtc.predict(x_test)\n",
    "    score.append(accuracy_score(y_test,pred)*100)\n",
    "print(\"i= \",np.argmax(score))\n",
    "print(score[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "322e0baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.24893071000855"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "x = data[\"Sentence\"]\n",
    "y = data[\"Sentiment\"]\n",
    "x = tfidf.fit_transform(x).toarray()\n",
    "y = le.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n",
    "\n",
    "model2 = dtc.fit(x_train,y_train)\n",
    "pred = model2.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91f8baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.06655253584421"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Accuracy\n",
    "\n",
    "pred = model2.predict(x_train)\n",
    "accuracy_score(y_train, pred)*100     #Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74024bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56470588 0.59786096 0.60320856 0.57922912 0.62526767]\n",
      "59.0\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n",
    "\n",
    "mod2 = cross_val_score(DecisionTreeClassifier(), x_train, y_train, cv=5)\n",
    "print(mod2)\n",
    "print(np.round(np.mean(mod2),2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d863d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef28056d",
   "metadata": {},
   "source": [
    "**RandomForest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c3a2e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.098374679213"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "model = rfc.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e312ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  4\n",
      "67.57912745936699\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(10):\n",
    "    x = data[\"Sentence\"]\n",
    "    y = data[\"Sentiment\"]\n",
    "    x = tfidf.fit_transform(x).toarray()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(x_train, y_train)\n",
    "    pred = rfc.predict(x_test)\n",
    "    score.append(accuracy_score(y_test,pred)*100)\n",
    "print(\"i= \",np.argmax(score))\n",
    "print(score[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d628653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.15141146278872"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "x = data[\"Sentence\"]\n",
    "y = data[\"Sentiment\"]\n",
    "x = tfidf.fit_transform(x).toarray()\n",
    "y = le.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n",
    "\n",
    "model3 = rfc.fit(x_train,y_train)\n",
    "pred = model3.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9561c816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.72416006847848"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Accuracy\n",
    "\n",
    "pred = model3.predict(x_train)\n",
    "accuracy_score(y_train, pred)*100     #Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d6d5104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64841745 0.63356164 0.65239726 0.63869863]\n",
      "64.0\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n",
    "\n",
    "mod3 = cross_val_score(RandomForestClassifier(), x_train, y_train, cv=4)\n",
    "print(mod3)\n",
    "print(np.round(np.mean(mod3),2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e73223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba451f99",
   "metadata": {},
   "source": [
    "**Gausian NB Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "102afb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.75962360992301"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "model = gnb.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5581bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  63\n",
      "49.700598802395206\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(100):\n",
    "    x = data[\"Sentence\"]\n",
    "    y = data[\"Sentiment\"]\n",
    "    x = tfidf.fit_transform(x).toarray()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    pred = gnb.predict(x_test)\n",
    "    score.append(accuracy_score(y_test,pred)*100)\n",
    "print(\"i= \",np.argmax(score))\n",
    "print(score[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73cc6e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.700598802395206"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "x = data[\"Sentence\"]\n",
    "y = data[\"Sentiment\"]\n",
    "x = tfidf.fit_transform(x).toarray()\n",
    "y = le.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n",
    "\n",
    "model4 = gnb.fit(x_train,y_train)\n",
    "pred = model4.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f8e65ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.93130751123475"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Accuracy\n",
    "\n",
    "pred = model4.predict(x_train)\n",
    "accuracy_score(y_train, pred)*100     #Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be80a9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44871795 0.44871795 0.42735043 0.44753747 0.44325482 0.46252677\n",
      " 0.44753747 0.46680942 0.47751606 0.46038544]\n",
      "45.0\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n",
    "\n",
    "mod4 = cross_val_score(GaussianNB(), x_train, y_train, cv=10)\n",
    "print(mod4)\n",
    "print(np.round(np.mean(mod4),2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16ab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeae51b3",
   "metadata": {},
   "source": [
    "**Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "898a0d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.43455945252353"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel=\"linear\",tol=0.1)\n",
    "model = svc.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc45811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  4\n",
      "70.91531223267751\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(5):\n",
    "    x = data[\"Sentence\"]\n",
    "    y = data[\"Sentiment\"]\n",
    "    x = tfidf.fit_transform(x).toarray()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    svc = SVC(kernel=\"linear\",tol=0.1)\n",
    "    svc.fit(x_train, y_train)\n",
    "    pred = svc.predict(x_test)\n",
    "    score.append(accuracy_score(y_test,pred)*100)\n",
    "print(\"i= \",np.argmax(score))\n",
    "print(score[np.argmax(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac9a724a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.91531223267751"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel=\"linear\",tol=0.1)\n",
    "x = data[\"Sentence\"]\n",
    "y = data[\"Sentiment\"]\n",
    "x = tfidf.fit_transform(x).toarray()\n",
    "y = le.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=np.argmax(score))\n",
    "\n",
    "model5 = svc.fit(x_train,y_train)\n",
    "pred = model5.predict(x_test)\n",
    "accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa6ee652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.21870318852986"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Accuracy\n",
    "\n",
    "pred = model5.predict(x_train)\n",
    "accuracy_score(y_train, pred)*100     #Generalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2768ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68006843 0.6875     0.68921233 0.69777397]\n",
      "69.0\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION TO CHECK WHETHER THE MODEL IS GENERALIZED OR NOT\n",
    "\n",
    "mod5 = cross_val_score(SVC(kernel=\"linear\",tol=0.1), x_train, y_train, cv=4)\n",
    "print(mod5)\n",
    "print(np.round(np.mean(mod5),2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb98f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ce364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
